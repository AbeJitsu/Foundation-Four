# Nginx Configuration - Your Application's Front Door
# Nginx is a high-performance web server that acts as a reverse proxy.
# Think of it as the bouncer and receptionist of your restaurant:
# - Greeter at the door (handles HTTPS security)
# - Traffic director (routes customers to the right place)
# - Menu board (serves static files)
# - Security guard (blocks bad requests)

# ============================================================================
# Worker Configuration - How Many Staff Members?
# ============================================================================
# worker_processes = number of worker processes that handle requests
# auto = one worker per CPU core (smart scaling based on hardware)
# Think of each worker as a staff member who can handle multiple customers

worker_processes auto;

# worker_connections = how many simultaneous customers each worker handles
# 1024 = each staff member can attend to 1024 customers at once
# Increase if you expect very high traffic

events {
  worker_connections 1024;
}

http {
  # ========================================================================
  # MIME Types and File Handling
  # ========================================================================
  # Tell Nginx what kind of files it's serving (images, CSS, JavaScript, etc)
  include /etc/nginx/mime.types;
  default_type application/octet-stream;

  # ========================================================================
  # Logging Setup
  # ========================================================================
  # access_log = record of every visitor (like a guest book)
  # error_log = when something goes wrong

  access_log /var/log/nginx/access.log;
  error_log /var/log/nginx/error.log warn;

  # ========================================================================
  # Performance Optimizations
  # ========================================================================

  # sendfile = use kernel optimization for sending files (faster downloads)
  # Like having an express lane for file delivery
  sendfile on;

  # tcp_nopush = bundle responses together (better use of network)
  # Like batching orders instead of sending them one by one
  tcp_nopush on;

  # tcp_nodelay = send small packets immediately (lower latency)
  # Even if the order is small, don't wait for it to fill up
  tcp_nodelay on;

  # Keep-alive = reuse connections (faster for multiple requests)
  # Like keeping the customer on the phone instead of hanging up
  keepalive_timeout 65;

  # ========================================================================
  # GZIP Compression - Make Files Smaller for Faster Downloads
  # ========================================================================
  # Think of this like vacuum-sealing your food for shipment
  # Compressed files are 70-80% smaller = 70-80% faster delivery
  # Only works for text-based files (HTML, CSS, JavaScript)

  gzip on;
  gzip_vary on;

  # Only compress if it saves space (min 256 bytes)
  gzip_min_length 256;

  # Compression level 6 = good balance between speed and compression
  # Range is 1-9 (higher = smaller but slower to compress)
  gzip_comp_level 6;

  # Which file types to compress
  gzip_types
    text/plain
    text/css
    text/xml
    text/javascript
    application/json
    application/javascript
    application/xml+rss
    application/rss+xml
    font/truetype
    font/opentype
    application/vnd.ms-fontobject
    image/svg+xml;

  # ========================================================================
  # Upstream Block - Where to Send Requests
  # ========================================================================
  # This tells Nginx: "When someone asks for the app, send them to..."
  # "app:3000" works because Docker creates a network where "app" is the hostname

  upstream app_backend {
    # app = name of the Next.js container
    # 3000 = port where Next.js is listening
    server app:3000;

    # keepalive = keep connections open between Nginx and the app
    # Reduces overhead of creating new connections
    keepalive 64;
  }

  # ========================================================================
  # HTTP Server (Port 80) - Redirect to HTTPS
  # ========================================================================
  # Everyone who tries to enter through the regular door gets redirected
  # to the secure door. This is a security best practice.
  # Never transmit sensitive data over unencrypted HTTP.

  server {
    listen 80;
    server_name _;

    # Redirect everything to HTTPS
    # $request_uri = the full path the user requested
    # permanent = HTTP 301 (search engines update their records)
    location / {
      return 301 https://$host$request_uri;
    }

    # Health check endpoint (doesn't need HTTPS)
    # Used by monitoring services to verify Nginx is running
    location /health {
      access_log off;
      return 200 "healthy\n";
      add_header Content-Type text/plain;
    }
  }

  # ========================================================================
  # HTTPS Server (Port 443) - The Main Entrance
  # ========================================================================
  # This is the secure, main entrance where all traffic is encrypted.
  # The padlock in your browser = this section working correctly.

  server {
    listen 443 ssl http2;
    server_name _;

    # ====================================================================
    # SSL Certificate Configuration
    # ====================================================================
    # In development: use self-signed certificates (test only)
    # In production: use Let's Encrypt (free, automatic renewal)
    # These paths are mounted as Docker volumes in docker-compose.yml

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    # ====================================================================
    # Security Headers - Tell Browsers How to Handle Content
    # ====================================================================
    # These prevent common attacks like clickjacking and XSS

    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # ====================================================================
    # Proxy Settings - Pass Requests to Next.js
    # ====================================================================
    # These tell the app: "Pass along important info about the original request"
    # Without these, the app might not know the user's real IP or that they used HTTPS

    # Add the original client's IP (so the app knows it's a real person)
    proxy_set_header X-Real-IP $remote_addr;

    # Add all proxy information (if request passed through multiple proxies)
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    # Tell the app: "This came through HTTPS"
    proxy_set_header X-Forwarded-Proto $scheme;

    # Add Host header (sometimes apps need to know which domain was requested)
    proxy_set_header Host $host;

    # Preserve the original request URI
    proxy_set_header X-Forwarded-URI $request_uri;

    # Keep-alive connections to the app (reduce connection overhead)
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    # Don't buffer the entire response before sending to client
    # Stream it directly = faster perceived load time
    proxy_buffering off;

    # ====================================================================
    # WebSocket Support - For Real-Time Features
    # ====================================================================
    # WebSockets need special handling for live updates (chat, notifications, etc)

    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;

    # Timeouts - how long to wait before giving up
    # 60s for regular requests, 3600s for WebSockets (they stay open)
    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;

    # ====================================================================
    # Static Files - Serve with Caching Headers
    # ====================================================================
    # Static files (images, fonts, CSS) rarely change
    # Cache them so browsers don't re-download every time

    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
      # Browser cache: keep for 1 year (in seconds)
      # Once a browser downloads it, don't ask for it again
      add_header Cache-Control "public, max-age=31536000, immutable";
      proxy_pass http://app_backend;
    }

    # ====================================================================
    # API Routes - No Caching (always fresh)
    # ====================================================================
    # API responses should never be cached by the browser
    # The server always needs to calculate the latest data

    location /api/ {
      add_header Cache-Control "no-cache, no-store, must-revalidate";
      proxy_pass http://app_backend;
    }

    # ====================================================================
    # Health Check Endpoint - Monitor the App
    # ====================================================================
    # Monitoring systems use this to verify the app is alive and healthy

    location /health {
      access_log off;
      proxy_pass http://app_backend;
    }

    # ====================================================================
    # Everything Else - Route to Next.js
    # ====================================================================
    # All other requests (pages, dynamic content) go to the app

    location / {
      proxy_pass http://app_backend;
    }
  }
}

# ============================================================================
# WebSocket Connection Upgrade Map
# ============================================================================
# This happens outside the http block so it's available to all servers
# Tells Nginx how to upgrade HTTP connections to WebSocket connections

map $http_upgrade $connection_upgrade {
  default upgrade;
  '' close;
}
